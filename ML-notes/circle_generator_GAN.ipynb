{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBUJYypchr6AehZbqGn05C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Amrollahi/Personal-Notes/blob/master/ML-notes/circle_generator_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rqcZ5xIblZao"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f_createRandomImage():\n",
        "    x,y = 35,35\n",
        "    max_r = 10\n",
        "    rangex, rangey = (max_r,x-max_r), (max_r,y-max_r)\n",
        "    colors = [((255, 255, 0),0),((120, 255,0),1),(( 255, 120,0),2),((0,255, 255),3),((0, 60, 60),4)]\n",
        "    lst_res = []\n",
        "    for color in colors:\n",
        "        for i in range(500):\n",
        "            \n",
        "            frame = np.full((x,y,3),1,dtype=\"uint8\")\n",
        "\n",
        "            locx = random.randint(*rangex)\n",
        "            locy = random.randint(*rangey)\n",
        "            r = random.randint(8,max_r)\n",
        "            \n",
        "            \n",
        "            cv2.circle(frame,(locx,locy),r,color[0],-1)\n",
        "\n",
        "            frame = frame / 255.0\n",
        "            #cv2.rectangle(frame,(locx-r,locy-r),(locx+r,locy+r),(0,255,0),1)\n",
        "            lst_res.append([frame.transpose(2,0,1), locx-r, locy-r, locx + r, locy + r, torch.nn.functional.one_hot(torch.tensor(color[1]), num_classes=5)])\n",
        "            #cv2.waitKey(0)\n",
        "\n",
        "    return lst_res"
      ],
      "metadata": {
        "id": "UwRmGbWAlpTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_modelD(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=6,kernel_size=(3,3)),\n",
        "            nn.BatchNorm2d(6),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=6, out_channels=12,kernel_size=(3,3)),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2,2),\n",
        "\n",
        "            nn.Flatten(1),\n",
        "\n",
        "            nn.Linear(15*15*12,128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128,1),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model.forward(x)"
      ],
      "metadata": {
        "id": "1N7uTCCNl41a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_modelG(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            \n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            #nn.ConvTranspose2d( 3, 3, 1,bias=False),\n",
        "            #nn.BatchNorm2d(3),\n",
        "            #nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            #nn.ConvTranspose2d( 3, 3, 1,bias=False),\n",
        "            nn.Conv2d(3,3,1),\n",
        "            nn.Tanh(),\n",
        "            #nn.Conv2d(3,3,1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            #nn.ReLU(True),\n",
        "            #nn.ReLU(),\n",
        "            nn.Conv2d(3, 3, 1),\n",
        "            nn.Sigmoid()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model.forward(x)"
      ],
      "metadata": {
        "id": "RtDNUqPYqC7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class cls_data(Dataset):\n",
        "    def __init__(self,x) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.dataset = x\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        return torch.tensor(self.dataset.loc[index, \"c\"]).unsqueeze(dim=0), torch.tensor(self.dataset.loc[index, \"image\"]).permute((2,0,1))"
      ],
      "metadata": {
        "id": "-7fC7W2FrlIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst_data = f_createRandomImage()\n",
        "\n",
        "x = torch.tensor([i[0] for i in lst_data]).float()\n",
        "\n",
        "trainLoader = DataLoader(x,batch_size=8)\n",
        "x.dtype"
      ],
      "metadata": {
        "id": "qm9n0alJrJGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelD = cls_modelD()\n",
        "criterion = nn.BCELoss()\n",
        "optimD = torch.optim.Adam(modelD.parameters(), lr=4e-4)\n",
        "\n",
        "modelG = cls_modelG()\n",
        "optimG = torch.optim.Adam(modelG.parameters(), lr=4e-4)"
      ],
      "metadata": {
        "id": "mMLAATKit-LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_label = 1.\n",
        "fake_label = 0."
      ],
      "metadata": {
        "id": "0anMIYXepQ_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "modelD = modelD.to(device)\n",
        "modelG = modelG.to(device)\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(30):\n",
        "    # For each batch in the dataloader\n",
        "    sum_err = 0\n",
        "    for i, data in enumerate(trainLoader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        optimD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data.to(device)\n",
        "        \n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,1), real_label, dtype=torch.float, device=device)\n",
        "        # Forward pass real batch through D\n",
        "        output = modelD(real_cpu)\n",
        "        # Calculate loss on all-real batch\n",
        "        \n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, 3, 35, 35, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = modelG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = modelD(fake.detach())\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        \n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimD.step()\n",
        "        \n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        optimG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = modelD(fake)\n",
        "        # Calculate G's loss based on this output\n",
        "        \n",
        "        \n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimG.step()\n",
        "\n",
        "        sum_err += errG.detach().cpu().item()\n",
        "    \n",
        "    print(sum_err)"
      ],
      "metadata": {
        "id": "dXiRD2fMsyPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelG.eval()\n",
        "fixed_noise = torch.randn((8,3,35,35)).to(device)\n",
        "\n",
        "res = modelG(fixed_noise)\n",
        "\n",
        "res = res*255\n",
        "\n",
        "res = res.type(torch.uint8)"
      ],
      "metadata": {
        "id": "SL24vZLTwMKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(res[6].permute(1,2,0).detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "vCW3hL5yAfox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
      ],
      "metadata": {
        "id": "pSvyUsC1qZ8h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1Q0pQo4qYsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}