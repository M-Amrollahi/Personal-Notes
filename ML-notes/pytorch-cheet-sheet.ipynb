{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Amrollahi/Personal-Notes/blob/master/ML-notes/pytorch-cheet-sheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BA-SwygEobyu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of elements  in tensor"
      ],
      "metadata": {
        "id": "P1-GIoTSMXdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F5E_rUoFobyx",
        "outputId": "1f925ae1-5b4a-41d5-bbc1-ab2083239953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "a = torch.arange(22)\n",
        "a.nelement()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flatten the tensor, starts from each dim"
      ],
      "metadata": {
        "id": "jB6oCzmuMfc2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gvNP8CUobyy",
        "outputId": "2fb60745-3f96-40dc-a92f-8f6b0968da43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.1783, 0.8209, 0.0261, 0.3833, 0.7992, 0.1784, 0.8311, 0.6818, 0.6363],\n",
              "        [0.1738, 0.1535, 0.6898, 0.9236, 0.3581, 0.2190, 0.3062, 0.9067, 0.4804],\n",
              "        [0.4577, 0.4426, 0.5322, 0.4159, 0.2990, 0.6162, 0.7050, 0.1627, 0.4601]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.flatten(torch.rand((3,3,3)) , start_dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk by number"
      ],
      "metadata": {
        "id": "LG0NhDAZMnNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrb210SZobyz",
        "outputId": "727e6259-1571-4340-e464-fdb37badbec6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4, 5, 6, 7]),\n",
              " tensor([ 8,  9, 10, 11, 12, 13, 14, 15]),\n",
              " tensor([16, 17, 18, 19, 20, 21]))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(22)\n",
        "a.chunk(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change the order of dims"
      ],
      "metadata": {
        "id": "1uYQRizyM14A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oVUNaV-obyz",
        "outputId": "94e51087-0c6d-49d5-de70-16e110b3a09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19],\n",
            "        [20, 21]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20],\n",
              "        [ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(a.view(11,2))\n",
        "torch.permute( a.view(11,2), dims=(1,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOTODBc9obyz",
        "outputId": "32ff0df3-c34d-4bde-aafb-523c752c65ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 2, 1, 0])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "z = torch.Generator().manual_seed(12)\n",
        "torch.randperm(4, generator= z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNsDXf_Yoby0"
      },
      "source": [
        "## if the type of the tensor is any kinds of float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNSfZXPAoby1",
        "outputId": "dfb4e562-526d-4ed8-9ddd-bb0e834c3308"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.is_floating_point()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6FBm0Qqoby2"
      },
      "source": [
        "## Convert object to tesor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlZ_5Sv-oby3",
        "outputId": "667f333b-f2ae-4836-ff32-e2e185103a87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.asarray((1,2,3,4.0))\n",
        "\n",
        "# keep grads\n",
        "torch.as_tensor([1,2,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL2OuFS8oby3"
      },
      "source": [
        "## Convert from np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChMnUZAIoby3",
        "outputId": "96190224-6367-4f4c-adaa-e6bf27fa4303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.from_numpy(np.arange(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5txrG_Foby4"
      },
      "source": [
        "## indeces of each non-zero element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2T5eNpcoby4",
        "outputId": "7bd0b315-0120-4006-cd27-c18bd6ccd8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19],\n",
            "        [20, 21]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 1,  0],\n",
              "        [ 1,  1],\n",
              "        [ 2,  0],\n",
              "        [ 2,  1],\n",
              "        [ 3,  0],\n",
              "        [ 3,  1],\n",
              "        [ 4,  0],\n",
              "        [ 4,  1],\n",
              "        [ 5,  0],\n",
              "        [ 5,  1],\n",
              "        [ 6,  0],\n",
              "        [ 6,  1],\n",
              "        [ 7,  0],\n",
              "        [ 7,  1],\n",
              "        [ 8,  0],\n",
              "        [ 8,  1],\n",
              "        [ 9,  0],\n",
              "        [ 9,  1],\n",
              "        [10,  0],\n",
              "        [10,  1]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(a.view(-1,2))\n",
        "a.view(-1,2).argwhere()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the tensor like in batch processing"
      ],
      "metadata": {
        "id": "TLLJnwmaNTfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.split(3)"
      ],
      "metadata": {
        "id": "iZVh5RxgNMlM",
        "outputId": "cf1f49c3-7e56-4337-9251-273eeea2054c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2]),\n",
              " tensor([3, 4, 5]),\n",
              " tensor([6, 7, 8]),\n",
              " tensor([ 9, 10, 11]),\n",
              " tensor([12, 13, 14]),\n",
              " tensor([15, 16, 17]),\n",
              " tensor([18, 19, 20]),\n",
              " tensor([21]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(10).reshape(5,2)\n",
        "a\n",
        "torch.split(a, 1)\n",
        "torch.split(a, [1,4])"
      ],
      "metadata": {
        "id": "386lUdkfOueT",
        "outputId": "67d0c272-42ac-44a5-aaa7-dc4385122160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0, 1]]),\n",
              " tensor([[2, 3],\n",
              "         [4, 5],\n",
              "         [6, 7],\n",
              "         [8, 9]]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptCTosiQoby4"
      },
      "source": [
        "## Horizontally split the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRSUWJOpoby5",
        "outputId": "8b8c081b-45a1-4ce0-ac0d-17caabe012ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.],\n",
              "         [ 4.,  5.],\n",
              "         [ 8.,  9.],\n",
              "         [12., 13.]]),\n",
              " tensor([[ 2.,  3.],\n",
              "         [ 6.,  7.],\n",
              "         [10., 11.],\n",
              "         [14., 15.]]))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.arange(16.0).reshape(4,4)\n",
        "t\n",
        "torch.hsplit(t, 2)\n",
        "#torch.hsplit(t, [3, 6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NtAVnD-oby5"
      },
      "source": [
        "## Split the tesnor in depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUmVa2kCoby5",
        "outputId": "3ab6e690-e81f-4d1f-fd8b-2d93b2cd4337"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 0.,  1.],\n",
              "          [ 4.,  5.]],\n",
              " \n",
              "         [[ 8.,  9.],\n",
              "          [12., 13.]]]),\n",
              " tensor([[[ 2.,  3.],\n",
              "          [ 6.,  7.]],\n",
              " \n",
              "         [[10., 11.],\n",
              "          [14., 15.]]]))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = torch.arange(16.0).reshape(2, 2, 4)\n",
        "t\n",
        "torch.dsplit(t, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gyHFJjyoby6"
      },
      "source": [
        "## Select the index by dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfdA3ifioby7",
        "outputId": "417384f3-a543-4030-a2db-881603aa3539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.9647, -0.2388,  0.4811,  0.2231],\n",
            "        [-1.1043, -0.4001, -1.9548, -0.8543],\n",
            "        [-0.9942,  1.1137, -0.1217, -0.7968]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9647,  0.4811],\n",
              "        [-1.1043, -1.9548],\n",
              "        [-0.9942, -0.1217]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x = torch.randn(3, 4)\n",
        "print(x)\n",
        "indices = torch.tensor([0, 2])\n",
        "#torch.index_select(x, 0, indices)\n",
        "torch.index_select(x, 1, indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7c-M700oby8"
      },
      "source": [
        "## select by mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzW9wWZtoby8",
        "outputId": "ff69a9f9-140b-4dc8-eafb-e2f6b0d4dbfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6199,  1.1587,  0.4375,  0.1795],\n",
            "        [ 2.0399,  1.6997, -0.2237, -0.5441],\n",
            "        [-0.8154,  1.0232, -1.1076, -0.0195]])\n",
            "tensor([[ True,  True, False, False],\n",
            "        [ True,  True, False, False],\n",
            "        [False,  True, False, False]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.6199, 1.1587, 2.0399, 1.6997, 1.0232])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x = torch.randn(3, 4)\n",
        "print(x)\n",
        "mask = x.ge(0.5)\n",
        "print(mask)\n",
        "torch.masked_select(x, mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CEMGjChoby9"
      },
      "source": [
        "## return the elemnts by the index view as 1-D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QoUUuQXoby9",
        "outputId": "5f039e26-1483-4d06-93cd-1725733e4da4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "src = torch.tensor([[4, 3, 5],\n",
        "                    [6, 7, 8]])\n",
        "torch.take(src, torch.tensor([0, 2, 5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQHMmh8oby-"
      },
      "source": [
        "## repeat the element of tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVRCg9Pmoby_",
        "outputId": "0798b717-b6a6-49d8-98ec-02bcb2dba838"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 1, 2],\n",
              "        [3, 4, 3, 4],\n",
              "        [1, 2, 1, 2],\n",
              "        [3, 4, 3, 4]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x.tile((2,))\n",
        "y = torch.tensor([[1, 2], [3, 4]])\n",
        "torch.tile(y, (2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdjn67z_obzA"
      },
      "source": [
        "## return the x, y based on conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO1yvu54obzA",
        "outputId": "52557849-4603-45a3-ed26-6be1a05e24fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000],\n",
              "        [0.9232, 0.0000]], dtype=torch.float64)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(3, 2)\n",
        "y = torch.ones(3, 2)\n",
        "x\n",
        "torch.where(x > 0, x, y)\n",
        "x = torch.randn(2, 2, dtype=torch.double)\n",
        "x\n",
        "torch.where(x > 0, x, 0.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvATFvpLobzB"
      },
      "source": [
        "## compute fractional part of the tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pyjZnbLobzB",
        "outputId": "ad081442-d781-4fd1-f17a-f644d5ce5b29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0000,  0.5000, -0.2000])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.frac(torch.tensor([1, 2.5, -3.2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyGJFhbuobzC"
      },
      "source": [
        "## fill the inf and nan with numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2cVIviyobzC",
        "outputId": "58ce8294-8311-4e2a-f27d-19401f7650af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 2.0000e+00,  1.0000e+00, -3.4028e+38,  3.1400e+00])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([float('nan'), float('inf'), -float('inf'), 3.14])\n",
        "torch.nan_to_num(x)\n",
        "torch.nan_to_num(x, nan=2.0)\n",
        "torch.nan_to_num(x, nan=2.0, posinf=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZR1moO9obzC"
      },
      "source": [
        "## return the sign of the tesnors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvzqjiq8obzC",
        "outputId": "05435561-6a2e-4c70-e334-51d5f7ee449e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1., -1.,  0.,  1.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([0.7, -1.2, 0., 2.3])\n",
        "a\n",
        "torch.sign(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24LC0oM_obzD"
      },
      "source": [
        "## integer part of tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6djpHfbBobzn",
        "outputId": "a854dba3-5ee7-436a-cd3a-61a71b6db6f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0., -0., -0., -1.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.randn(4)\n",
        "a\n",
        "torch.trunc(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsL7cJEjobzp"
      },
      "source": [
        "## return the product of the tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1FkM7qjobzp",
        "outputId": "a733da6b-4e51-4ea0-e60e-06037c265eaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.0147)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.randn(1, 3)\n",
        "a\n",
        "torch.prod(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ_szhprobzq"
      },
      "source": [
        "## count non zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tsXB3a2obzq",
        "outputId": "02023740-1aad-4849-c39b-bdfc7209bd0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.zeros(3,3)\n",
        "x[torch.randn(3,3) > 0.5] = 1\n",
        "x\n",
        "torch.count_nonzero(x)\n",
        "torch.count_nonzero(x, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpO4HOSnobzq"
      },
      "source": [
        "## equal element wise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxBvtSWJobzr",
        "outputId": "4efe352e-3b4c-46c4-db6d-228f5d139b23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ True, False],\n",
              "        [False,  True]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88RgwiUzobzr"
      },
      "source": [
        "## unflatten any dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43SlmFx8obzs",
        "outputId": "d0ec6996-37f4-4032-d906-6dc798560980"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 2, 2, 3, 1, 1, 3])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.randn(5, 12, 3)\n",
        "torch.unflatten(a, 1, (2, 2, 3, 1, 1)).shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find contiguous in memory"
      ],
      "metadata": {
        "id": "oeMUqdosPfKj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-be9GobXobzs",
        "outputId": "bc8918a7-7d69-482c-fe33-cafea1d38036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## Make the elements in memory is a raw\n",
        "## https://stackoverflow.com/questions/48915810/what-does-contiguous-do-in-pytorch\n",
        "a = torch.randint(1,10,(3,3))\n",
        "a.contiguous()\n",
        "a.is_contiguous()\n",
        "\n",
        "a.T.is_contiguous()\n",
        "\n",
        "# How to move to achieve the next element in each dim\n",
        "a.stride()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expand to new size. Do not allocate memory!"
      ],
      "metadata": {
        "id": "fj8lnfSuwEma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1], [2], [3]])\n",
        "x.size()\n",
        "x.expand(3, 4)"
      ],
      "metadata": {
        "id": "JNF8mG00v5mc",
        "outputId": "27548ff8-9a5f-4560-f020-7754bcae481f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [2, 2, 2, 2],\n",
              "        [3, 3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import profiler\n",
        "\n",
        "l1 = torch.nn.Linear(3,2,bias=True)\n",
        "a = torch.randn((3,3))\n",
        "# Enable the profiler\n",
        "with profiler.profile(use_cuda=False) as prof:\n",
        "    l1(a)\n",
        "\n",
        "\n",
        "# Print the profiling results\n",
        "print(prof)\n"
      ],
      "metadata": {
        "id": "szOyNIg1wLbX",
        "outputId": "4e69414a-aa12-4bff-e691-03ceab5d4672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
            "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "          aten::linear         8.92%      14.000us       100.00%     157.000us     157.000us             1  \n",
            "               aten::t        18.47%      29.000us        29.94%      47.000us      47.000us             1  \n",
            "       aten::transpose         7.01%      11.000us        11.46%      18.000us      18.000us             1  \n",
            "      aten::as_strided         4.46%       7.000us         4.46%       7.000us       7.000us             1  \n",
            "           aten::addmm        47.13%      74.000us        61.15%      96.000us      96.000us             1  \n",
            "          aten::expand         2.55%       4.000us         3.18%       5.000us       5.000us             1  \n",
            "      aten::as_strided         0.64%       1.000us         0.64%       1.000us       1.000us             1  \n",
            "           aten::copy_        10.19%      16.000us        10.19%      16.000us      16.000us             1  \n",
            "    aten::resolve_conj         0.64%       1.000us         0.64%       1.000us       1.000us             1  \n",
            "    aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us             1  \n",
            "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 157.000us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mat1 @ mat2 + M"
      ],
      "metadata": {
        "id": "x4QPJkIuy_Qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = torch.randn(2, 3)\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.addmm(M, mat1, mat2)"
      ],
      "metadata": {
        "id": "OLgHXPLwyWDk",
        "outputId": "cde165e4-2da0-48c5-a325-97115de2702a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9562, -1.4567, -0.7769],\n",
              "        [ 0.2622,  1.0937,  3.3500]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To check the bottleneck of the code"
      ],
      "metadata": {
        "id": "hlOH7ru91l4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m torch.utils.bottleneck /path/to/source/script.py [args]"
      ],
      "metadata": {
        "id": "NUml-7D9yzpt",
        "outputId": "467d0dd3-667e-4021-f7fb-5268d9892d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-400e03718d79>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -m torch.utils.bottleneck /path/to/source/script.py [args]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## how to save and load pytorch model"
      ],
      "metadata": {
        "id": "0r1OdiDe31hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save checkpoint\n",
        "checkpoint = {\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss,\n",
        "    # Add any other information you want to save\n",
        "}\n",
        "torch.save(checkpoint, 'checkpoint.pth')\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load('checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "# Continue training or perform inference\n"
      ],
      "metadata": {
        "id": "nx-jnIf83tBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use quantization model\n",
        "Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. A quantized model executes some or all of the operations on tensors with reduced precision rather than full precision (floating point) values. This allows for a more compact model representation and the use of high performance vectorized operations on many hardware platforms. PyTorch supports INT8 quantization compared to typical FP32 models allowing for a 4x reduction in the model size and a 4x reduction in memory bandwidth requirements. Hardware support for INT8 computations is typically 2 to 4 times faster compared to FP32 compute. Quantization is primarily a technique to speed up inference and only the forward pass is supported for quantized operators.\n",
        "\n"
      ],
      "metadata": {
        "id": "8ktINLiAED0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.quantization\n",
        "\n",
        "# Define a simple model\n",
        "class MyModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc = torch.nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()\n",
        "\n",
        "# Create a random input tensor\n",
        "input_tensor = torch.randn(1, 10)\n",
        "\n",
        "# Perform the forward pass\n",
        "output = model(input_tensor)\n",
        "\n",
        "# Apply post-training static quantization\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# Create a random input tensor for the quantized model\n",
        "quantized_input_tensor = input_tensor#torch.randn(1, 10)\n",
        "\n",
        "# Perform the forward pass on the quantized model\n",
        "quantized_output = quantized_model(quantized_input_tensor)\n",
        "\n",
        "# Print the original and quantized outputs\n",
        "print(\"Original output:\", output)\n",
        "print(\"Quantized output:\", quantized_output)\n"
      ],
      "metadata": {
        "id": "j_p33hDw8e-u",
        "outputId": "187acd0b-0efb-490c-c640-7dd253957612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original output: tensor([[ 0.6606, -0.2118, -0.1486, -0.9009, -0.2390]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Quantized output: tensor([[ 0.6513, -0.2097, -0.1451, -0.9051, -0.2283]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6j8jnHf8i0N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10 (default, Feb 26 2021, 10:16:00) \n[Clang 10.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f3e886644a3928785097e4f2b76d86ea4f5782e84190f8a407df728a5fcc7bf0"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}