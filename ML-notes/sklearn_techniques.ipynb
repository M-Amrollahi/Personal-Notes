{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWSzWoqMroq0ZgSWf/L4S9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Amrollahi/Personal-Notes/blob/master/ML-notes/sklearn_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use FunctionTransformer to set custom transformer"
      ],
      "metadata": {
        "id": "tQQx_2RWICrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ4QRMKmsI8A",
        "outputId": "4447080c-5788-4723-eb58-1caace7b4ebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Generate some random data\n",
        "X = np.random.normal(0, 5, size=(100,))\n",
        "\n",
        "transformer = FunctionTransformer(func=np.exp,\n",
        "                                  inverse_func=np.log,\n",
        "                                  )\n",
        "\n",
        "x_log = transformer.transform(X)\n",
        "X_new = transformer.inverse_transform(x_log)\n",
        "\n",
        "np.allclose(X, X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to set parameters for FunctionTransformer"
      ],
      "metadata": {
        "id": "JcqEOniEK-YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Define a custom function to normalize data\n",
        "def normalize(X):\n",
        "    return (X - np.mean(X, axis=0)) / np.std(X, axis=0), np.mean(X, axis=0),np.std(X, axis=0)\n",
        "\n",
        "def inverse_normalize(X_norm, mu, sigma):\n",
        "    X = X_norm * sigma + mu\n",
        "    return X\n",
        "\n",
        "# Create a FunctionTransformer object to apply normalization\n",
        "transformer = FunctionTransformer(normalize, inverse_func=inverse_normalize)\n",
        "\n",
        "# Generate some random data\n",
        "X = np.random.normal(0, 1, size=(100, 3))\n",
        "\n",
        "# Apply the transformer to the input data\n",
        "X_transformed,x_mean,x_std = transformer.transform(X)\n",
        "transformer.inv_kw_args = {\"mu\": x_mean, \"sigma\": x_std}\n",
        "\n",
        "# Apply the inverse transformation to the transformed data\n",
        "X_inverse = transformer.inverse_transform(X_transformed)\n",
        "\n",
        "# Check if the original data is equal to the inverse-transformed data\n",
        "np.allclose(X, X_inverse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs8O-nSz2Ah0",
        "outputId": "e58b289e-8f50-4dd8-9fac-5d3063b60275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Generate some random data with a non-Gaussian distribution\n",
        "X = np.random.gamma(1, size=(100, 3))\n",
        "\n",
        "# Create a PowerTransformer object\n",
        "transformer = PowerTransformer()\n",
        "\n",
        "# Apply the transformer to the input data\n",
        "X_transformed = transformer.fit_transform(X)\n",
        "\n",
        "# Print the mean and standard deviation of the transformed data\n",
        "print(\"Mean:\", np.mean(X_transformed, axis=0))\n",
        "print(\"Standard deviation:\", np.std(X_transformed, axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e87MS7bXEQlP",
        "outputId": "8f6fcf42-3519-4db8-e252-39b105a8a441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: [-2.49800181e-17  1.20681243e-15 -3.04756220e-16]\n",
            "Standard deviation: [1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting Classifier , StackingClassifier"
      ],
      "metadata": {
        "id": "AnTatM62ARYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000)\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        (\"xgb\", xgb.XGBClassifier(eval_metric=\"auc\")),\n",
        "        (\"lgbm\", lgbm.LGBMClassifier()),\n",
        "        (\"cb\", cb.CatBoostClassifier(verbose=False)),\n",
        "    ],\n",
        "    voting=\"soft\",\n",
        "    # n_jobs=-1,\n",
        ")\n",
        "\n",
        "_ = ensemble.fit(X, y)\n",
        "\n",
        "#######\n",
        "ensemble = StackingClassifier(\n",
        "    estimators=[\n",
        "        (\"xgb\", xgb.XGBClassifier(eval_metric=\"auc\")),\n",
        "        (\"lgbm\", lgbm.LGBMClassifier()),\n",
        "        (\"cb\", cb.CatBoostClassifier(verbose=False)),\n",
        "    ],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5,\n",
        "    passthrough=False\n",
        "    # n_jobs=-1,\n",
        ")\n",
        "\n",
        "_ = ensemble.fit(X, y)"
      ],
      "metadata": {
        "id": "vn_TPTetNT2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "105dc6d8-def8-4821-948a-63e398160a29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-291f5ce82a6e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     estimators=[\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#(\"xgb\", xgb.XGBClassifier(eval_metric=\"auc\")),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"lgbm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m\"cb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     ],\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lgbm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA, tSNE, UMAP for dim resuction"
      ],
      "metadata": {
        "id": "J48hX9SV8BO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#######"
      ],
      "metadata": {
        "id": "LluQEM0PBteW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting outliers\n",
        "As for LocalOutlierFactor, it is a neighbors-based algorithm designed to work fast with large datasets."
      ],
      "metadata": {
        "id": "dYQ4M1xpBppJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import umap  # pip install umap\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "X, y = make_classification(n_samples=5000, n_classes=2, n_features=10)\n",
        "X_reduced = umap.UMAP(n_components=2).fit_transform(X, y)\n",
        "\n",
        "lof = LocalOutlierFactor()\n",
        "labels = lof.fit_predict(X_reduced, y)"
      ],
      "metadata": {
        "id": "WUqdBppw5KJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using joblib module to save the model in sklearn"
      ],
      "metadata": {
        "id": "xKLVNMHzQX8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from joblib import dump\n",
        "\n",
        "# Load a sample dataset\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train a model\n",
        "model = svm.SVC()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Save the model to a file\n",
        "dump(model, 'model.joblib')\n"
      ],
      "metadata": {
        "id": "xMI1Kq1dBvVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}